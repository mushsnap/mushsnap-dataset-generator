

# Scrapping


## Steps

1. Retrieve spieces (names to look)
2. Retrieve urls
3. Retrieve images
4. Create dataset
5. Create Mini-batches

## Libraries

To execute all the tasks to retrieve all aspects i have use scrapper libreries such as selenium for Websites with the ChromeDriver and Flickr to retrieve the images.

### References

- Flickr (Images) - FLickrAPI
- Spieces (Names) - http://www.mushroom.world/mushrooms
- Selenium (Library - Chrome automatitaion)

## Pre-process

- https://github.com/selvam85/Cat-Dog-Classifier/blob/master/DNN_using_plain_TF_Cat_vs_Dog_classifier_Kaggle_dataset/Convert%20Images%20to%20Numpy%20array%20and%20save%20in%20h5%20fomat%20v2.1.ipynb

## FLICKR-API

- [Flickr api](https://www.flickr.com/services/api/)

- [Search Method](https://www.flickr.com/services/api/flickr.photos.search.html)

To modify the size of the image that is retrieve.
- [Url parameters](https://www.flickr.com/services/api/misc.urls.html)


## Other datasets

- https://www.kaggle.com/maysee/mushrooms-classification-common-genuss-images

